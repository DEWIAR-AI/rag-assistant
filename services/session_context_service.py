import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from sqlalchemy.orm import Session
from database.database import SessionLocal
from database.models import Conversation, ConversationMessage, Document
from services.embedding_service import embedding_service
import json
import re

logger = logging.getLogger(__name__)


class SessionContextService:
    """Manages session context and conversational memory for RAG system"""
    
    def __init__(self):
        self.session_cache = {}  # In-memory cache for active sessions
    
    def get_db_session(self):
        """Get a database session"""
        return SessionLocal()
    
    async def get_or_create_conversation(self, session_id: str, user_id: int, 
                                       initial_context: Optional[str] = None) -> Dict[str, Any]:
        """Get existing conversation or create new one - returns plain dict, not SQLAlchemy object"""
        try:
            db = self.get_db_session()
            try:
                # Try to find existing conversation
                conversation = db.query(Conversation).filter(
                    Conversation.session_id == session_id
                ).first()
                
                if conversation:
                    # Update last activity
                    conversation.last_activity = datetime.now()
                    db.commit()
                    logger.info(f"üìù Retrieved existing conversation: {session_id}")
                    
                    # Return as plain dict to avoid session binding issues
                    return {
                        'id': conversation.id,
                        'session_id': conversation.session_id,
                        'user_id': conversation.user_id,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º user_id –≤–º–µ—Å—Ç–æ access_token_id
                        'title': conversation.title,
                        'user_context': conversation.user_context,
                        'current_section': conversation.current_section,
                        'document_context': conversation.document_context or [],
                        'search_context': conversation.search_context or [],
                        'created_at': conversation.created_at,
                        'last_activity': conversation.last_activity
                    }
                else:
                    # Create new conversation
                    conversation = Conversation(
                        session_id=session_id,
                        user_id=user_id,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º user_id
                        title="New Conversation",
                        user_context=initial_context,
                        document_context=[],
                        search_context=[],
                        current_section=None
                    )
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)
                    logger.info(f"üÜï Created new conversation: {session_id}")
                    
                    # Return as plain dict
                    return {
                        'id': conversation.id,
                        'session_id': conversation.session_id,
                        'user_id': conversation.user_id,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º user_id –≤–º–µ—Å—Ç–æ access_token_id
                        'title': conversation.title,
                        'user_context': conversation.user_context,
                        'current_section': conversation.current_section,
                        'document_context': conversation.document_context or [],
                        'search_context': conversation.search_context or [],
                        'created_at': conversation.created_at,
                        'last_activity': conversation.last_activity
                    }
                    
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"‚ùå Failed to get/create conversation: {e}")
            raise
    
    def _clean_text_for_database(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö Unicode —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î"""
        if not text:
            return text
        
        try:
            # –£–¥–∞–ª—è–µ–º NULL —Å–∏–º–≤–æ–ª—ã –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            cleaned = text.replace('\u0000', '')  # NULL —Å–∏–º–≤–æ–ª
            cleaned = cleaned.replace('\u0001', '')  # START OF HEADING
            cleaned = cleaned.replace('\u0002', '')  # START OF TEXT
            cleaned = cleaned.replace('\u0003', '')  # END OF TEXT
            cleaned = cleaned.replace('\u0004', '')  # END OF TRANSMISSION
            cleaned = cleaned.replace('\u0005', '')  # ENQUIRY
            cleaned = cleaned.replace('\u0006', '')  # ACKNOWLEDGE
            cleaned = cleaned.replace('\u0007', '')  # BELL
            cleaned = cleaned.replace('\u0008', '')  # BACKSPACE
            cleaned = cleaned.replace('\u0009', '')  # HORIZONTAL TAB
            cleaned = cleaned.replace('\u000A', '')  # LINE FEED
            cleaned = cleaned.replace('\u000B', '')  # VERTICAL TAB
            cleaned = cleaned.replace('\u000C', '')  # FORM FEED
            cleaned = cleaned.replace('\u000D', '')  # CARRIAGE RETURN
            cleaned = cleaned.replace('\u000E', '')  # SHIFT OUT
            cleaned = cleaned.replace('\u000F', '')  # SHIFT IN
            
            # –£–¥–∞–ª—è–µ–º –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            cleaned = cleaned.replace('\u0010', '')  # DATA LINK ESCAPE
            cleaned = cleaned.replace('\u0011', '')  # DEVICE CONTROL ONE
            cleaned = cleaned.replace('\u0012', '')  # DEVICE CONTROL TWO
            cleaned = cleaned.replace('\u0013', '')  # DEVICE CONTROL THREE
            cleaned = cleaned.replace('\u0014', '')  # DEVICE CONTROL FOUR
            cleaned = cleaned.replace('\u0015', '')  # NEGATIVE ACKNOWLEDGE
            cleaned = cleaned.replace('\u0016', '')  # SYNCHRONOUS IDLE
            cleaned = cleaned.replace('\u0017', '')  # END OF TRANSMISSION BLOCK
            cleaned = cleaned.replace('\u0018', '')  # CANCEL
            cleaned = cleaned.replace('\u0019', '')  # END OF MEDIUM
            cleaned = cleaned.replace('\u001A', '')  # SUBSTITUTE
            cleaned = cleaned.replace('\u001B', '')  # ESCAPE
            cleaned = cleaned.replace('\u001C', '')  # FILE SEPARATOR
            cleaned = cleaned.replace('\u001D', '')  # GROUP SEPARATOR
            cleaned = cleaned.replace('\u001E', '')  # RECORD SEPARATOR
            cleaned = cleaned.replace('\u001F', '')  # UNIT SEPARATOR
            
            # –£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã DEL –∏ –≤—ã—à–µ 0x7F (–Ω–µ-ASCII)
            cleaned = ''.join(char for char in cleaned if ord(char) < 0x7F or ord(char) > 0x9F)
            
            # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            import re
            cleaned = re.sub(r'\s+', ' ', cleaned)
            cleaned = cleaned.strip()
            
            return cleaned
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é –≤–µ—Ä—Å–∏—é
            return text[:1000] if text else ""  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    
    def _clean_search_results(self, search_results: Any) -> Any:
        """–û—á–∏—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –æ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if not search_results:
            return search_results
        
        try:
            if isinstance(search_results, str):
                # –ï—Å–ª–∏ —ç—Ç–æ JSON —Å—Ç—Ä–æ–∫–∞, –ø–∞—Ä—Å–∏–º –∏ –æ—á–∏—â–∞–µ–º
                import json
                try:
                    parsed = json.loads(search_results)
                    return self._clean_search_results(parsed)
                except:
                    # –ï—Å–ª–∏ –Ω–µ JSON, –æ—á–∏—â–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                    return self._clean_text_for_database(search_results)
            
            elif isinstance(search_results, list):
                cleaned_list = []
                for item in search_results:
                    if isinstance(item, dict):
                        cleaned_item = {}
                        for key, value in item.items():
                            if key == 'content' and isinstance(value, str):
                                cleaned_item[key] = self._clean_text_for_database(value)
                            else:
                                cleaned_item[key] = value
                        cleaned_list.append(cleaned_item)
                    else:
                        cleaned_list.append(item)
                return cleaned_list
            
            elif isinstance(search_results, dict):
                cleaned_dict = {}
                for key, value in search_results.items():
                    if key == 'content' and isinstance(value, str):
                        cleaned_dict[key] = self._clean_text_for_database(value)
                    else:
                        cleaned_dict[key] = value
                return cleaned_dict
            
            else:
                return search_results
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    async def add_message_to_conversation(self, conversation_id: int, role: str, content: str,
                                        search_context: Optional[Dict] = None) -> ConversationMessage:
        """Add a message to the conversation with search context"""
        try:
            db = self.get_db_session()
            try:
                # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î
                cleaned_content = self._clean_text_for_database(content)
                cleaned_search_query = self._clean_text_for_database(search_context.get('query') if search_context else None)
                cleaned_search_results = self._clean_search_results(search_context.get('results') if search_context else None)
                cleaned_used_sections = search_context.get('sections') if search_context else None
                
                message = ConversationMessage(
                    conversation_id=conversation_id,
                    role=role,
                    content=cleaned_content,
                    search_query=cleaned_search_query,
                    search_results=cleaned_search_results,
                    used_sections=cleaned_used_sections,
                    context_relevance_score=search_context.get('relevance_score') if search_context else None,
                    source_chunks=search_context.get('source_chunks') if search_context else None,
                    source_documents=search_context.get('source_documents') if search_context else None
                )
                
                db.add(message)
                db.commit()
                db.refresh(message)
                
                # Update conversation last activity - use the same session
                try:
                    conversation = db.query(Conversation).filter(Conversation.id == conversation_id).first()
                    if conversation:
                        conversation.last_activity = datetime.now()
                        db.commit()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not update conversation last activity: {e}")
                
                logger.info(f"üí¨ Added {role} message to conversation {conversation_id}")
                return message
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"‚ùå Failed to add message: {e}")
            raise
    
    async def get_conversation_context(self, session_id: str, 
                                     max_messages: int = 10) -> Dict[str, Any]:
        """Get conversation context including history and document memory"""
        try:
            db = self.get_db_session()
            try:
                conversation = db.query(Conversation).filter(
                    Conversation.session_id == session_id
                ).first()
                
                if not conversation:
                    return {
                        'session_id': session_id,
                        'messages': [],
                        'document_context': [],
                        'current_section': None,
                        'search_context': []
                    }
                
                # Get recent messages
                messages = db.query(ConversationMessage).filter(
                    ConversationMessage.conversation_id == conversation.id
                ).order_by(ConversationMessage.created_at.desc()).limit(max_messages).all()
                
                # Reverse to get chronological order
                messages = list(reversed(messages))
                
                # Extract document context from messages - convert to plain dicts
                document_context = []
                search_context = []
                
                for msg in messages:
                    if msg.search_results:
                        # Add document content from previous searches
                        # Convert SQLAlchemy objects to plain dicts
                        search_results = msg.search_results
                        if isinstance(search_results, str):
                            try:
                                import json
                                search_results = json.loads(search_results)
                            except:
                                search_results = []
                        
                        if isinstance(search_results, list):
                            for result in search_results:
                                if isinstance(result, dict) and 'content' in result:
                                    doc_info = {
                                        'content': result['content'],
                                        'document_id': result.get('document_id'),
                                        'section': result.get('section'),
                                        'score': result.get('score', 0.0),
                                        'timestamp': msg.created_at.isoformat(),
                                        'query': msg.search_query
                                    }
                                    document_context.append(doc_info)
                        
                        # Add search context
                        if msg.search_query:
                            used_sections = msg.used_sections
                            if isinstance(used_sections, str):
                                try:
                                    import json
                                    used_sections = json.loads(used_sections)
                                except:
                                    used_sections = []
                            
                            search_context.append({
                                'query': msg.search_query,
                                'sections': used_sections,
                                'timestamp': msg.created_at.isoformat()
                            })
                
                # Convert conversation to plain dict
                conversation_dict = {
                    'id': conversation.id,
                    'session_id': conversation.session_id,
                    'title': conversation.title,
                    'current_section': conversation.current_section,
                    'user_context': conversation.user_context,
                    'created_at': conversation.created_at.isoformat() if conversation.created_at else None,
                    'last_activity': conversation.last_activity.isoformat() if conversation.last_activity else None
                }
                
                return {
                    'session_id': session_id,
                    'conversation_id': conversation.id,
                    'messages': [
                        {
                            'role': msg.role,
                            'content': msg.content,
                            'timestamp': msg.created_at.isoformat()
                        } for msg in messages
                    ],
                    'document_context': document_context,
                    'current_section': conversation.current_section,
                    'search_context': search_context
                }
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"‚ùå Failed to get conversation context: {e}")
            return {
                'session_id': session_id,
                'messages': [],
                'document_context': [],
                'current_section': None,
                'search_context': []
            }
    
    async def update_conversation_section(self, session_id: str, section: str) -> bool:
        """Update the current section being discussed in the conversation"""
        try:
            db = self.get_db_session()
            try:
                conversation = db.query(Conversation).filter(
                    Conversation.session_id == session_id
                ).first()
                
                if conversation:
                    conversation.current_section = section
                    conversation.last_activity = datetime.now()
                    db.commit()
                    logger.info(f"üéØ Updated conversation {session_id} section to: {section}")
                    return True
                return False
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"‚ùå Failed to update conversation section: {e}")
            return False
    
    async def should_use_existing_context(self, session_id: str, new_query: str, 
                                        threshold: float = 0.6) -> Tuple[bool, List[Dict], str]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å–ª–µ–¥—É–µ—Ç –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–º–µ—Å—Ç–æ –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å_—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π, –¥–∞–Ω–Ω—ã–µ_–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è)"""
        try:
            context = await self.get_conversation_context(session_id)
            
            if not context['document_context']:
                logger.info("üì≠ –ù–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - –≤—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫")
                return False, [], "new_search"
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–≤—è–∑–∞–Ω –ª–∏ –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            if len(context['messages']) < 2:
                logger.info("üìù –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π - –≤—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫")
                return False, [], "new_search"
            
            # –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            last_user_message = None
            for msg in reversed(context['messages']):
                if msg['role'] == 'user':
                    last_user_message = msg['content']
                    break
            
            if not last_user_message:
                logger.info("üìù –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –≤—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫")
                return False, [], "new_search"
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            is_clarifying = self._is_clarifying_question(new_query, last_user_message)
            
            if is_clarifying:
                logger.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å: '{new_query}' -> '{last_user_message}'")
                logger.info(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —É—Ç–æ—á–Ω—è—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞")
                return True, context['document_context'], "context_reuse"
            
            # –í—ã—á–∏—Å–ª–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            try:
                similarity = await self._calculate_query_similarity(last_user_message, new_query)
                logger.info(f"üìä –°—Ö–æ–¥—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {similarity:.3f} (–ø–æ—Ä–æ–≥: {threshold})")
                
                if similarity > threshold:
                    logger.info(f"üîÑ –í—ã—Å–æ–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ ({similarity:.3f}) - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç")
                    return True, context['document_context'], "context_reuse"
                elif similarity > 0.3:  # –°—Ä–µ–¥–Ω–µ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ - –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥
                    logger.info(f"üîÑ –°—Ä–µ–¥–Ω–µ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ ({similarity:.3f}) - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç")
                    return True, context['document_context'], "hybrid_context"
                else:
                    logger.info(f"üÜï –ù–∏–∑–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ ({similarity:.3f}) - –≤—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫")
                    return False, [], "new_search"
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ: {e}")
                # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: –µ—Å–ª–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–µ —É–¥–∞–ª–æ—Å—å, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è
                if self._is_clarifying_question(new_query, last_user_message):
                    logger.info(f"üîÑ –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —É—Ç–æ—á–Ω–µ–Ω–∏—è")
                    return True, context['document_context'], "context_reuse"
                return False, [], "new_search"
                
        except Exception as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
            return False, [], "new_search"
    
    async def _calculate_query_similarity(self, query1: str, query2: str) -> float:
        """Calculate semantic similarity between two queries"""
        try:
            # Get embeddings for both queries
            embedding1 = await embedding_service.get_embeddings_async(query1)
            embedding2 = await embedding_service.get_embeddings_async(query2)
            
            # Calculate cosine similarity
            import numpy as np
            
            # Convert to numpy arrays
            vec1 = np.array(embedding1)
            vec2 = np.array(embedding2)
            
            # Calculate cosine similarity
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            similarity = dot_product / (norm1 * norm2)
            return float(similarity)
            
        except Exception as e:
            logger.error(f"‚ùå Failed to calculate similarity: {e}")
            return 0.0
    
    async def merge_contexts(self, existing_context: List[Dict], new_results: List[Dict],
                            max_context_size: int = 20) -> List[Dict]:
        """Merge existing context with new search results"""
        try:
            # Combine contexts
            merged = existing_context + new_results
            
            # Remove duplicates based on document_id and content
            seen = set()
            unique_context = []
            
            for item in merged:
                key = (item.get('document_id'), item.get('content', '')[:100])
                if key not in seen:
                    seen.add(key)
                    unique_context.append(item)
            
            # Sort by relevance score and timestamp
            unique_context.sort(key=lambda x: (
                x.get('score', 0),
                x.get('timestamp', '')
            ), reverse=True)
            
            # Limit context size
            return unique_context[:max_context_size]
            
        except Exception as e:
            logger.error(f"‚ùå Failed to merge contexts: {e}")
            return new_results
    
    async def cleanup_old_sessions(self, max_age_hours: int = 24) -> int:
        """Clean up old inactive sessions"""
        try:
            db = self.get_db_session()
            try:
                cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
                
                # Find old conversations
                old_conversations = db.query(Conversation).filter(
                    Conversation.last_activity < cutoff_time
                ).all()
                
                deleted_count = 0
                for conv in old_conversations:
                    db.delete(conv)
                    deleted_count += 1
                
                db.commit()
                logger.info(f"üßπ Cleaned up {deleted_count} old sessions")
                return deleted_count
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"‚ùå Failed to cleanup old sessions: {e}")
            return 0

    async def clear_document_context(self, session_id: str) -> bool:
        """–û—á–∏—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏"""
        try:
            db = self.get_db_session()
            try:
                conversation = db.query(Conversation).filter(
                    Conversation.session_id == session_id
                ).first()
                
                if conversation:
                    conversation.document_context = []
                    conversation.search_context = []
                    db.commit()
                    logger.info(f"üßπ –û—á–∏—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")
                    return True
                else:
                    logger.warning(f"‚ö†Ô∏è –°–µ—Å—Å–∏—è {session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
                    return False
                    
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return False

    def _is_clarifying_question(self, new_query: str, previous_query: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≤–æ–ø—Ä–æ—Å —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            new_lower = new_query.lower().strip()
            prev_lower = previous_query.lower().strip()
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω 1: –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —É—Ç–æ—á–Ω—è—é—â–∏—Ö —Å–ª–æ–≤
            clarifying_starters = [
                '–∞ —á—Ç–æ', '–∞ –µ—Å–ª–∏', '–∞ –∫–∞–∫', '–∞ –∫–æ–≥–¥–∞', '–∞ –≥–¥–µ', '–∞ –ø–æ—á–µ–º—É',
                '–∞ –∫–∞–∫–∞—è', '–∞ –∫–∞–∫–∏–µ', '–∞ –∫–∞–∫–æ–π', '–∞ –∫–∞–∫–æ–µ', '–∞ —Å–∫–æ–ª—å–∫–æ',
                '—á—Ç–æ –Ω–∞—Å—á–µ—Ç', '–∫–∞–∫ –Ω–∞—Å—á–µ—Ç', '—Ä–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ', '–æ–±—ä—è—Å–Ω–∏',
                '—á—Ç–æ –∏–º–µ–Ω–Ω–æ', '—á—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ', '—á—Ç–æ —Ç—ã –∏–º–µ–µ—à—å –≤ –≤–∏–¥—É',
                '–∞', '–Ω–æ', '–æ–¥–Ω–∞–∫–æ', '—Ç–∞–∫–∂–µ', '–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ', '–µ—â–µ',
                '–∏ —á—Ç–æ', '–∏ –∫–∞–∫', '–∏ –∫–æ–≥–¥–∞', '–∏ –≥–¥–µ', '–∏ –ø–æ—á–µ–º—É'
            ]
            
            for starter in clarifying_starters:
                if new_lower.startswith(starter):
                    logger.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω —É—Ç–æ—á–Ω—è—é—â–∏–π —Å—Ç–∞—Ä—Ç–µ—Ä: '{starter}'")
                    return True
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω 2: –°–æ–¥–µ—Ä–∂–∏—Ç —É—Ç–æ—á–Ω—è—é—â–∏–µ –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è, —Å—Å—ã–ª–∞—é—â–∏–µ—Å—è –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            clarifying_pronouns = [
                '—ç—Ç–æ', '—Ç–æ', '—ç—Ç–∏', '—Ç–µ', '–æ–Ω–æ', '–æ–Ω–∏', '–∏—Ö',
                '–≤—ã—à–µ—É–ø–æ–º—è–Ω—É—Ç–æ–µ', '—É–ø–æ–º—è–Ω—É—Ç–æ–µ', '–ø—Ä–µ–¥—ã–¥—É—â–µ–µ', '—Ç–æ –∂–µ —Å–∞–º–æ–µ',
                '–¥–∞–Ω–Ω—ã–π', '–¥–∞–Ω–Ω–∞—è', '–¥–∞–Ω–Ω–æ–µ', '–¥–∞–Ω–Ω—ã–µ'
            ]
            
            for pronoun in clarifying_pronouns:
                if pronoun in new_lower:
                    logger.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —É—Ç–æ—á–Ω—è—é—â–µ–µ –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ: '{pronoun}'")
                    return True
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω 3: –û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ, –≤–µ—Ä–æ—è—Ç–Ω–æ, —è–≤–ª—è—é—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏—è–º–∏
            if len(new_lower.split()) <= 3 and any(word in new_lower for word in ['—á—Ç–æ', '–∫–∞–∫', '–ø–æ—á–µ–º—É', '–∫–æ–≥–¥–∞', '–≥–¥–µ', '–∫–∞–∫–æ–π', '–∫–∞–∫–∞—è', '–∫–∞–∫–æ–µ']):
                logger.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω –∫–æ—Ä–æ—Ç–∫–∏–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å: '{new_lower}'")
                return True
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω 4: –í–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å—Å—ã–ª–∞—é—Ç—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            # –ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            prev_nouns = re.findall(r'\b\w+(?:\s+\w+)*\b', prev_lower)
            prev_nouns = [noun for noun in prev_nouns if len(noun) > 3 and noun not in ['—á—Ç–æ', '–∫–æ–≥–¥–∞', '–≥–¥–µ', '–∫–∞–∫', '–ø–æ—á–µ–º—É', '–æ', '—Å', '–æ—Ç', '–≤', '–≤–æ', '–Ω–∞', '–∑–∞', '–ø–æ–¥', '–Ω–∞–¥', '–ø–µ—Ä–µ–¥', '–ø–æ—Å–ª–µ', '–º–µ–∂–¥—É', '—Å—Ä–µ–¥–∏', '—á–µ—Ä–µ–∑', '–≤–æ–ø—Ä–µ–∫–∏', '–∫', '–ø–æ', '–Ω–∞']]
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ª—é–±–æ–µ –∏–∑ —ç—Ç–∏—Ö —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö
            for noun in prev_nouns[:5]:  # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–≤—ã–µ 5 —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö
                if noun in new_lower:
                    logger.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç: '{noun}' –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
                    return True
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω 5: –í–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è –ø—Ä—è–º—ã–º–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è–º–∏
            follow_up_patterns = [
                (r'–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è.*–≤—ã—Å–æ—Ç–∞', r'–≤—ã—Å–æ—Ç–∞.*–ø–æ—Ç–æ–ª–∫–∞'),
                (r'—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è.*–ø–æ–º–µ—â–µ–Ω–∏—è', r'–≤—ã—Å–æ—Ç–∞.*–ø–æ—Ç–æ–ª–∫–∞'),
                (r'–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å.*–ø—Ä–æ–¥—É–∫—Ç–æ–≤', r'–≥–∏–≥–∏–µ–Ω–∏—á–µ—Å–∫–∏–µ.*–ø—Ä–∞–∫—Ç–∏–∫–∏'),
                (r'—Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã', r'–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ.*–ø—Ä–∞–∫—Ç–∏–∫–∏'),
                (r'–ø—Ä–æ—Ü–µ–¥—É—Ä—ã', r'–¥–µ—Ç–∞–ª—å–Ω—ã–µ.*—à–∞–≥–∏'),
                (r'—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è.*–∫–æ–º–Ω–∞—Ç—ã', r'–≤—ã—Å–æ—Ç–∞.*–ø–æ—Ç–æ–ª–∫–∞'),
                (r'—Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã.*–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏', r'–≥–∏–≥–∏–µ–Ω–∏—á–µ—Å–∫–∏–µ.*–º–µ—Ä—ã')
            ]
            
            for prev_pattern, new_pattern in follow_up_patterns:
                if re.search(prev_pattern, prev_lower) and re.search(new_pattern, new_lower):
                    logger.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è: '{prev_pattern}' -> '{new_pattern}'")
                    return True
            
            logger.info(f"üîç –£—Ç–æ—á–Ω—è—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥–ª—è: '{new_lower}'")
            return False
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ —É—Ç–æ—á–Ω—è—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞: {e}")
            return False


# Global instance
session_context_service = SessionContextService()
