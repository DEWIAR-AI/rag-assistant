#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —á–∞—Ç–µ
"""

import base64
import io
import logging
import tempfile
import os
from typing import Dict, Any, List, Optional, Tuple
from PIL import Image
import mimetypes

# OCR imports
try:
    from paddleocr import PaddleOCR
    PADDLE_AVAILABLE = True
except ImportError:
    PADDLE_AVAILABLE = False

try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False

logger = logging.getLogger(__name__)


class ImageProcessingService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —á–∞—Ç–µ"""
    
    def __init__(self):
        self.ocr_engine = None
        self._initialize_ocr()
    
    def _initialize_ocr(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OCR –¥–≤–∏–∂–∫–∞"""
        try:
            logger.info("üîß Initializing OCR engines...")
            
            # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º PaddleOCR –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –ø—É—Ç—è–º–∏ –∫ –º–æ–¥–µ–ª—è–º
            logger.info("PaddleOCR temporarily disabled due to model path issues")
            
            if TESSERACT_AVAILABLE:
                try:
                    logger.info("üîÑ Trying Tesseract...")
                    version = pytesseract.get_tesseract_version()
                    logger.info(f"‚úÖ Tesseract version {version} found")
                    self.ocr_engine = 'tesseract'
                    logger.info("‚úÖ Tesseract OCR initialized successfully")
                    return
                except Exception as e:
                    logger.warning(f"Tesseract not available: {e}")
                    self.ocr_engine = None
            
            logger.warning("‚ùå No OCR engines available")
            logger.info(f"PADDLE_AVAILABLE: {PADDLE_AVAILABLE}")
            logger.info(f"TESSERACT_AVAILABLE: {TESSERACT_AVAILABLE}")
                
        except Exception as e:
            logger.error(f"OCR initialization failed: {e}")
            self.ocr_engine = None
    
    def process_chat_images(self, images: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —á–∞—Ç–∞ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
        if not images:
            logger.info("No images to process")
            return {}
        
        logger.info(f"Processing {len(images)} images...")
        
        results = {
            'total_images': len(images),
            'processed_images': 0,
            'extracted_text': [],
            'image_analysis': [],
            'errors': []
        }
        
        for i, image_data in enumerate(images):
            try:
                logger.info(f"Processing image {i+1}/{len(images)}")
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                image_result = self._process_single_image(image_data, i)
                results['image_analysis'].append(image_result)
                results['processed_images'] += 1
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                if image_result.get('extracted_text'):
                    results['extracted_text'].append(image_result['extracted_text'])
                    logger.info(f"Image {i+1} extracted text length: {len(image_result['extracted_text'])}")
                else:
                    logger.warning(f"Image {i+1} no text extracted")
                    
            except Exception as e:
                error_msg = f"Error processing image {i}: {str(e)}"
                logger.error(error_msg)
                results['errors'].append(error_msg)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–µ—Å—å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        if results['extracted_text']:
            results['combined_text'] = '\n\n'.join(results['extracted_text'])
            logger.info(f"Combined text length: {len(results['combined_text'])}")
        
        logger.info(f"Processing complete: {results['processed_images']}/{results['total_images']} images processed")
        return results
    
    def _process_single_image(self, image_data, index: int) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ image_data Pydantic –º–æ–¥–µ–ª—å—é –∏–ª–∏ —Å–ª–æ–≤–∞—Ä–µ–º
            if hasattr(image_data, 'image_data'):
                # Pydantic –º–æ–¥–µ–ª—å
                image_bytes = base64.b64decode(image_data.image_data)
                image_type = image_data.image_type
                description = image_data.description
            else:
                # –°–ª–æ–≤–∞—Ä—å
                image_bytes = base64.b64decode(image_data['image_data'])
                image_type = image_data.get('image_type', 'image/jpeg')
                description = image_data.get('description', '')
            
            logger.info(f"Image {index}: decoded {len(image_bytes)} bytes")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(delete=False, suffix=self._get_file_extension(image_type)) as temp_file:
                temp_file.write(image_bytes)
                temp_file_path = temp_file.name
                logger.info(f"Image {index}: saved to {temp_file_path}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–ª—Å—è –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ
            if os.path.exists(temp_file_path):
                file_size = os.path.getsize(temp_file_path)
                logger.info(f"Image {index}: file exists, size={file_size} bytes")
            else:
                logger.error(f"Image {index}: file was not created!")
                return {
                    'index': index,
                    'error': 'Temporary file was not created',
                    'extracted_text': '',
                    'text_confidence': 0.0
                }
            
            try:
                # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                image = Image.open(io.BytesIO(image_bytes))
                logger.info(f"Image {index}: opened successfully, size={image.size}, mode={image.mode}")
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                analysis = {
                    'index': index,
                    'image_type': image_type,
                    'dimensions': image.size,
                    'mode': image.mode,
                    'description': description,
                    'extracted_text': '',
                    'text_confidence': 0.0,
                    'objects_detected': [],
                    'processing_time': 0.0
                }
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ OCR
                if self.ocr_engine:
                    logger.info(f"Processing image {index} with OCR engine: {type(self.ocr_engine)}")
                    extracted_text, confidence = self._extract_text_from_image(temp_file_path)
                    analysis['extracted_text'] = extracted_text
                    analysis['text_confidence'] = confidence
                    logger.info(f"Image {index} OCR result: text length={len(extracted_text)}, confidence={confidence}")
                else:
                    logger.warning(f"No OCR engine available for image {index}")
                
                # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                analysis['objects_detected'] = self._analyze_image_content(image)
                
                return analysis
                
            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                try:
                    os.unlink(temp_file_path)
                    logger.info(f"Image {index}: temporary file deleted")
                except:
                    pass
                    
        except Exception as e:
            logger.error(f"Error processing image {index}: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return {
                'index': index,
                'error': str(e),
                'extracted_text': '',
                'text_confidence': 0.0
            }
    
    def _extract_text_from_image(self, image_path: str) -> Tuple[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            if isinstance(self.ocr_engine, PaddleOCR):
                return self._extract_text_with_paddle(image_path)
            elif self.ocr_engine == 'tesseract':
                return self._extract_text_with_tesseract(image_path)
            else:
                return "", 0.0
                
        except Exception as e:
            logger.error(f"Error extracting text: {e}")
            return "", 0.0
    
    def _extract_text_with_paddle(self, image_path: str) -> Tuple[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é PaddleOCR"""
        try:
            result = self.ocr_engine.ocr(image_path, cls=True)
            
            if not result or not result[0]:
                return "", 0.0
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            texts = []
            confidences = []
            
            for line in result[0]:
                if line and len(line) >= 2:
                    text = line[1][0]  # –¢–µ–∫—Å—Ç
                    confidence = line[1][1]  # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                    texts.append(text)
                    confidences.append(confidence)
            
            combined_text = '\n'.join(texts)
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
            
            return combined_text, avg_confidence
            
        except Exception as e:
            logger.error(f"PaddleOCR error: {e}")
            return "", 0.0
    
    def _extract_text_with_tesseract(self, image_path: str) -> Tuple[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é Tesseract"""
        try:
            # –ü—Ä–æ–±—É–µ–º –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è —è–∑—ã–∫–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            text = pytesseract.image_to_string(
                image_path, 
                config='--psm 6 --oem 3'
            )
            
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
            if not text.strip():
                text = pytesseract.image_to_string(
                    image_path, 
                    config='--psm 6'
                )
            
            # –ï—Å–ª–∏ –∏ —ç—Ç–æ –Ω–µ –ø–æ–º–æ–≥–ª–æ, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            if not text.strip():
                text = pytesseract.image_to_string(image_path)
            
            # Tesseract –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É: –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω, —Å—á–∏—Ç–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å—Ä–µ–¥–Ω–µ–π
            confidence = 0.7 if text.strip() else 0.0
            
            logger.info(f"Tesseract extracted text: '{text.strip()}' (confidence: {confidence})")
            return text.strip(), confidence
            
        except Exception as e:
            logger.error(f"Tesseract error: {e}")
            return "", 0.0
    
    def _analyze_image_content(self, image: Image.Image) -> List[str]:
        """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        objects = []
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã
            width, height = image.size
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
            if width > height * 1.5:
                objects.append("landscape")
            elif height > width * 1.5:
                objects.append("portrait")
            else:
                objects.append("square")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ü–≤–µ—Ç–∞
            if image.mode == 'RGB':
                # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö —Ü–≤–µ—Ç–æ–≤
                colors = image.getcolors(maxcolors=1000)
                if colors:
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–∏–∫—Å–µ–ª–µ–π
                    colors.sort(key=lambda x: x[0], reverse=True)
                    dominant_color = colors[0][1]
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è—Ä–∫–æ—Å—Ç—å
                    r, g, b = dominant_color
                    brightness = (r + g + b) / 3
                    
                    if brightness > 200:
                        objects.append("light")
                    elif brightness < 50:
                        objects.append("dark")
                    else:
                        objects.append("medium_brightness")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∂–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if image.mode == 'L':
                objects.append("grayscale")
            elif image.mode == 'RGBA':
                objects.append("with_transparency")
            
        except Exception as e:
            logger.warning(f"Error analyzing image content: {e}")
        
        return objects
    
    def _get_file_extension(self, mime_type: str) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–æ MIME —Ç–∏–ø—É"""
        ext = mimetypes.guess_extension(mime_type)
        return ext if ext else '.jpg'
    
    def enhance_chat_context(self, message: str, image_analysis: Dict[str, Any]) -> str:
        """–£–ª—É—á—à–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —á–∞—Ç–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö"""
        if not image_analysis or not image_analysis.get('extracted_text'):
            return message
        
        enhanced_message = message + "\n\n"
        enhanced_message += "üì∏ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:\n"
        
        for i, img_analysis in enumerate(image_analysis.get('image_analysis', []), 1):
            if img_analysis.get('extracted_text'):
                enhanced_message += f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i}:\n"
                enhanced_message += f"–¢–µ–∫—Å—Ç: {img_analysis['extracted_text'][:200]}...\n"
                enhanced_message += f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {img_analysis.get('text_confidence', 0):.2f}\n\n"
        
        return enhanced_message


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
image_processing_service = ImageProcessingService()
